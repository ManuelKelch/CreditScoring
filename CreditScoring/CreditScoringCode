import numpy as np
import sklearn as sk
from sklearn import tree
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import GridSearchCV
from sklearn.neural_network import MLPClassifier


def get_optimal_params_for_clf(samples,labels):
    # scale samples
    mlp = MLPClassifier(max_iter=10000)
    samples_scaled = sk.preprocessing.scale(samples)
    print(samples_scaled)
    params = {
        'hidden_layer_sizes': [(9,), (21,), (30,)],
        'activation': ['tanh', 'relu', 'logistic'],
        'solver': ['sgd', 'adam'],
    }
    # split up data for test and training
    X_train, X_test, y_train, y_test = sk.model_selection.train_test_split(samples_scaled, labels, test_size=0.3333, random_state=1)

    clf = GridSearchCV(mlp, params, n_jobs=-1, cv=5)
    clf.fit(X_train, y_train)
    # Best parameter set
    print('Best parameters found:\n', clf.best_params_,"%0.3f"% clf.best_score_)

    # All results
    means = clf.cv_results_['mean_test_score']
    stds = clf.cv_results_['std_test_score']
    for mean, std, params in zip(means, stds, clf.cv_results_['params']):
        print("%0.3f (+/-%0.03f) for %r" % (mean, std * 2, params))


def preprocessing(samples,labels,clf):
    samples_std = sk.preprocessing.scale(samples)
    samples_norm = sk.preprocessing.normalize(samples)

    x_train, x_test, y_train, y_test = sk.model_selection.train_test_split(samples, labels, test_size=0.3333, random_state=1)
    x_train_std, x_test_std, y_train_std, y_test_std = sk.model_selection.train_test_split(samples_std, labels, test_size=0.3333, random_state=1)
    x_train_norm, x_test_norm, y_train_norm, y_test_norm = sk.model_selection.train_test_split(samples_norm, labels, test_size=0.3333, random_state=1)

    clf.fit(x_train,y_train)
    pred = clf.predict(x_test)
    clf.fit(x_train_std,y_train_std)
    pred_std = clf.predict(x_test_std)
    clf.fit(x_train_norm,y_train_norm)
    pred_norm = clf.predict(x_test_norm)


    scores1 = cross_val_score(clf, samples, labels, cv=20, scoring='accuracy')
    scores2 = cross_val_score(clf, samples, labels, cv=20, scoring='precision')

    scores1_std = cross_val_score(clf, samples_std, labels, cv=20, scoring='accuracy')
    scores2_std = cross_val_score(clf, samples_std, labels, cv=20, scoring='precision')

    scores1_norm = cross_val_score(clf, samples_norm, labels, cv=20, scoring='accuracy')
    scores2_norm = cross_val_score(clf, samples_norm, labels, cv=20, scoring='precision')

    print('CV Accuracy normal: ' + "{:.9f}".format(scores1.mean()))
    print('CV Precision normal: ' + "{:.9f}".format(scores2.mean()))
    print('accuracy score normal: ' + "{:.9f}".format(sk.metrics.accuracy_score(y_test,pred)))
    print('CV Accuracy standardized: ' + "{:.9f}".format(scores1_std.mean()))
    print('CV Precision standardized: ' + "{:.9f}".format(scores2_std.mean()))
    print('accuracy score standardized: ' + "{:.9f}".format(sk.metrics.accuracy_score(y_test_std, pred_std)))
    print('CV Accuracy normalized: ' + "{:.9f}".format(scores1_norm.mean()))
    print('CV Precision normalized: ' + "{:.9f}".format(scores2_norm.mean()))
    print('accuracy score normal: ' + "{:.9f}".format(sk.metrics.accuracy_score(y_test_norm, pred_norm)))
def testNeuralNetwork():
    mlp = MLPClassifier(max_iter=10000, hidden_layer_sizes=(30,), activation="relu", solver='sgd')
    mlp1 = MLPClassifier(max_iter=10000, shuffle=True, hidden_layer_sizes=(9,), activation='tanh', solver='sgd')
    X_train, X_test, y_train, y_test = sk.model_selection.train_test_split(samples_scaled, labels, test_size=0.3333,
                                                                           random_state=1)
    mlp.fit(X_train, y_train)
    mlp1.fit(X_train,y_train)
    predictions = mlp.predict(X_test)
    predictions1 = mlp1.predict(X_test)
    score = sk.metrics.accuracy_score(y_test, predictions)
    score1 = sk.metrics.accuracy_score(y_test, predictions1)
    print(score)
    print(score1)

dataset = np.genfromtxt('german_credit.csv', delimiter=',', skip_header = 1)
labels = dataset[:, 0]
samples = np.delete(dataset, 0, 1)
samples_scaled = sk.preprocessing.scale(samples)

#preprocessing(samples,labels,dec_tree)
#get_optimal_params_for_clf(samples,labels)
#testNeuralNetwork()


